{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIaMOG31xnch27FyPJcqmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xketh/Fatec_PLN/blob/main/Aula_12_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objetivo**\n",
        "\n",
        "* Criar um programa que consegue adivinhar a próxima palavra de uma frase usando um tipo especial de cérebro de computador chamado Rede Neural Recorrente (RNN).\n",
        "\n",
        "* Criar outro programa que consegue dizer se uma frase é feliz ou triste (sentimento positivo ou negativo) usando uma versão mais esperta dessa rede, chamada LSTM.\n",
        "\n",
        "Para fazer isso, vamos usar ferramentas chamadas TensorFlow e Keras, que ajudam a construir e ensinar essas redes de computador.\n",
        "\n",
        "\n",
        "### **Explicação dos termos:**\n",
        "\n",
        "* **Rede Neural Recorrente (RNN):**\n",
        "É um tipo de cérebro de computador que entende sequências, como frases. Ele lembra as palavras que vieram antes para ajudar a escolher a próxima palavra certa.\n",
        "\n",
        "* **TensorFlow/Keras:** São programas que ajudam a criar e ensinar essas redes neurais de forma mais fácil, como kits de ferramentas para construir máquinas inteligentes.\n",
        "\n",
        "* **Rede Long Short-Term Memory (LSTM):** É uma versão mais esperta da RNN que consegue lembrar melhor coisas importantes por mais tempo, assim entende frases e sentimentos com mais precisão."
      ],
      "metadata": {
        "id": "2S3vweLZ-8tr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Etapas de Desenvolvimento (Fluxo do Programa):**"
      ],
      "metadata": {
        "id": "m_yGdVOQTty2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação: RNN Simples para Previsão da Próxima Palavra**\n",
        "\n",
        "1. **Preparar os dados:** Reunir um conjunto de textos e organizá-los de forma adequada para ensinar a rede neural.\n",
        "\n",
        "2. **Criar o modelo RNN:**\n",
        "Planejar e construir o formato básico do cérebro artificial que será usado.\n",
        "\n",
        "3. **Ensinar/Treinar o modelo:** Usar os textos organizados para treinar a rede neural, mostrando como ela deve funcionar.\n",
        "\n",
        "4. **Avaliação de desempenho:** Testar o que a rede aprendeu e verificar se está boa para prever a próxima palavra corretamente.\n",
        "\n",
        "5. **Testar o modelo:** Dar frases diferentes ao modelo para ver como ele se sai na previsão de palavras.\n"
      ],
      "metadata": {
        "id": "9pvlcK0hLuZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação: LSTMs para Classificação de Sentimentos**\n",
        "\n",
        "1. **Preparar os dados:** Reunir frases já classificadas como \"positivas\" ou \"negativas\" e prepará-las (limpar e organizar) para serem usadas no treinamento.\n",
        "\n",
        "2. **Criar o modelo LSTM:** Desenhar a estrutura do modelo LSTM, especificando como ele vai processar as frases para identificar os sentimentos.\n",
        "\n",
        "3. **Ensinar/Treinar o modelo:** Ensinar o modelo LSTM a reconhecer padrões nos sentimentos das frases usando os dados preparados.\n",
        "\n",
        "4. **Avaliação de desempenho:** Medir o quão bem o modelo consegue identificar sentimentos corretamente com base nos dados usados no treinamento.\n",
        "\n",
        "5. **Teste do Modelo:** Colocar o modelo à prova usando frases novas, que ele ainda não viu, para verificar se consegue classificar os sentimentos com precisão.\n"
      ],
      "metadata": {
        "id": "c6jxAH0wHyMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação 1: Modelo de Rede Neural de Recorrência**"
      ],
      "metadata": {
        "id": "B3xne5gmJPfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1° Passo: Configuração de Ambiente no Google Colab**"
      ],
      "metadata": {
        "id": "vAp2WFTgJjhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print(\"Bibliotecas importadas com sucesso\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0FrUTbAJe7j",
        "outputId": "1d764f69-5aff-4c1b-a596-dbfcd67eaebb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resumo do que o código está executando:**\n",
        "\n",
        "---\n",
        "\n",
        "O código está preparando um programa para trabalhar com texto e redes neurais, sendo assim o programa começa importando tudo isso para criar algo que entende e analisa melhor as frases.\n",
        "\n",
        "\n",
        "* **numpy:** Uma ferramenta que ajuda o computador a fazer cálculos com números rapidamente.\n",
        "\n",
        "* **tensorflow.keras:** Um conjunto de ferramentas que facilita criar e ensinar \"cérebros\" artificiais (modelos de deep learning > sistemas de computador que aprendem a resolver problemas complexos, como reconhecer imagens ou entender texto, imitando o funcionamento do cérebro humano.).\n",
        "\n",
        "* **Embedding:** Transforma palavras em números que fazem sentido para o computador.\n",
        "\n",
        "* **SimpleRNN:** É como um \"cérebro\" simples que entende sequências, como frases.\n",
        "\n",
        "* **Dense:** Uma parte do \"cérebro\" que ajuda a tomar decisões.\n",
        "\n",
        "* **Tokenizer:** Uma ferramenta que traduz texto em números, como se fosse um tradutor de palavras para códigos.\n",
        "\n",
        "* **pad_sequences:** Garante que todas as frases tenham o mesmo tamanho, adicionando zeros no final se necessário."
      ],
      "metadata": {
        "id": "7RlbqqrtKAow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2° Passo: Preparação do Conjunto de Dados**"
      ],
      "metadata": {
        "id": "BV0nig-HM5An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de dados de treinamento (pequeno e simplificado)\n",
        "\n",
        "textos_treinamento = [\n",
        "    \"eu gosto de programar em python\",\n",
        "    \"python é uma linguagem poderosa\",\n",
        "    \"programar é divertido com python\",\n",
        "    \"aprenda python e seja feliz\",\n",
        "    \"gosto de aprender coisas novas\"\n",
        "]\n",
        "print(f\"Textos de treinamento: {textos_treinamento}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MSP7E2tNA61",
        "outputId": "fbfcc7a9-cda1-4c9a-c632-8b33362627c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textos de treinamento: ['eu gosto de programar em python', 'python é uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Construir o vocabulário a partir dos textos\n",
        "tokenizer.fit_on_texts(textos_treinamento)\n",
        "\n",
        "# Converter textos em sequências de números\n",
        "sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n",
        "\n",
        "# Imprimir o vocabulário e as sequências geradas\n",
        "print(f\"\\nVocabulário (palavra:índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequencias numéricas dos textos: {sequencias}\")\n",
        "\n",
        "# Calcular o tamanho do vocabulário (+1 para incluir o 0 de padding)\n",
        "\n",
        "total_palavras = len(tokenizer.word_index) + 1\n",
        "print(f\"Tamanho total do vocabulário: {total_palavras}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYpvk7FTNN-a",
        "outputId": "018a4bc3-2273-4c71-eefd-0f2e982a2d3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra:índice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'é': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'divertido': 11, 'com': 12, 'aprenda': 13, 'e': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n",
            "Sequencias numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 5, 11, 12, 1], [13, 1, 14, 15, 16], [2, 3, 17, 18, 19]]\n",
            "Tamanho total do vocabulário: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar Entradas (X) e saídas (y) para a previsão da próxima palavra\n",
        "# a entrada (X) será uma sequência de palavras, e a saída (y) será a palavra seguinte\n",
        "# Determninar o comprimento máximo das sequências para padding\n",
        "\n",
        "max_comprimento = max(len(seq) for seq in sequencias)\n",
        "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
        "\n",
        "# Criar pares de entrada (sequencia parcial) e saída (próxima palavra)\n",
        "# Ex: \"eu gosto de programar\" -> \"em\"\n",
        "#  \"eu gosto de programar em\" -> \"python\"\n",
        "\n",
        "entradas_X = []\n",
        "saidas_y = []\n",
        "\n",
        "for seq in sequencias:\n",
        "  for i in range(1, len(seq)):\n",
        "    entradas_X.append(seq[:i]) # A sequencia até a palavra atual\n",
        "    saidas_y.append(seq[i])    # a proxima palavra\n",
        "\n",
        "print(f\"Exemplo de entradas_x (parcial): {entradas_X[0:5]}\")\n",
        "print(f\"Exemplo de entradas_y (parcial): {saidas_y[0:5]}\")\n",
        "\n",
        "# Padronizar o comprimento das sequências de entrada\n",
        "# Todas as sequências de entrada precisam ter o mesmo comprimento para RNN\n",
        "entradas_X_padded = pad_sequences(entradas_X, maxlen=max_comprimento -1, padding='pre')\n",
        "# O maxlen é 'max_comprimento -1 ' porque a saída 'y' é a ultima palavra, então x sempre terá 1 palavra a menos.\n",
        "\n",
        "# Converter as saídas para o formato one-hot encoding\n",
        "# Isso é necessário para a camada de saída da RNN(softmax)\n",
        "saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
        "\n",
        "print(f\"\\nExemplo de entradas_x_padded (após padding e truncagem): \\n{entradas_X_padded[0:5]}\")\n",
        "print(f\"\\nExemplo de saidas_y_one_hot (após one-hot encoding): \\n{saidas_y_one_hot[0:5]}\")\n",
        "print(f\"\\nFormato final das entradas (X): {entradas_X_padded.shape}\")\n",
        "print(f\"\\nExemplo final das saídas (y): {saidas_y_one_hot.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZSpqSTbNSgN",
        "outputId": "7bdc1256-ad19-47db-c096-8cc8d135b19c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências antes do padding: 6\n",
            "Exemplo de entradas_x (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
            "Exemplo de entradas_y (parcial): [2, 3, 4, 7, 1]\n",
            "\n",
            "Exemplo de entradas_x_padded (após padding e truncagem): \n",
            "[[0 0 0 0 6]\n",
            " [0 0 0 6 2]\n",
            " [0 0 6 2 3]\n",
            " [0 6 2 3 4]\n",
            " [6 2 3 4 7]]\n",
            "\n",
            "Exemplo de saidas_y_one_hot (após one-hot encoding): \n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            "Formato final das entradas (X): (21, 5)\n",
            "\n",
            "Exemplo final das saídas (y): (21, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resumo do que o código está executando:**\n",
        "\n",
        "---\n",
        "\n",
        "* **Transformamos frases em pares:** uma parte da frase já conhecida e a palavra que vem em seguida.\n",
        "\n",
        "* **Usamos o pad_sequences:** que adiciona zeros no início das frases menores para que fiquem do mesmo tamanho.\n",
        "\n",
        "* **Usamos to_categorical:** que cria um código especial onde só a posição da palavra certa é marcada com \"1\", e o resto fica \"0\"."
      ],
      "metadata": {
        "id": "Gzjvc5nNODP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3° Passo: Construção do Modelo RNN**"
      ],
      "metadata": {
        "id": "npP3_TtLPRKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o modelo\n",
        "# Definir a arquitetura do modelo RNN\n",
        "modelo_rnn = Sequential()\n",
        "\n",
        "# Camada de Embedding:\n",
        "# total_palavras: tamanho vocabulario\n",
        "# 10: dimensão do vetor de embedding (quantas características queremos para cada palavra)\n",
        "# input_lenght: comprimento das sequencias de entrada (maxlen - 1)\n",
        "modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_X_padded.shape[1]))\n",
        "\n",
        "# Camada SimpleRNN:\n",
        "# 32: número de unidades (neurônios) na camada recorrente. Este é o tamanho do estado oculto.\n",
        "modelo_rnn.add(SimpleRNN(32))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# total_palavras: número de neurônios de saída (um para cada palavra no vocabulário)\n",
        "# activation='softmax': função de ativação para probabilidade (soma 1 para todas as palavras)\n",
        "modelo_rnn.add(Dense(total_palavras, activation='softmax'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_rnn.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "RSjV9UtmPn2v",
        "outputId": "98893ce2-1bae-40ab-d78d-6b8bff128660"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resumo do que o código está executando:**\n",
        "\n",
        "---\n",
        "\n",
        "* **Camada de Embedding:** Transforma cada palavra em números especiais que mostram o significado dela, para o computador entender melhor as relações entre palavras parecidas.\n",
        "\n",
        "* **Camada SimpleRNN:** Lê as palavras uma por uma e lembra do que já viu, como uma memória que ajuda a entender a frase toda.\n",
        "\n",
        "* **Camada Dense (final):** Usa a memória da etapa anterior para decidir qual palavra pode vir a seguir, dando uma \"pontuação\" para cada palavra possível, que soma 100%.  Ela recebe o vetor do estado oculto final da RNN. Esse vetor resume as informações que a RNN \"lembrou\" da sequência de palavras processada."
      ],
      "metadata": {
        "id": "tweVKQYxPv1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4° Passo: Treinamento do Modelo**"
      ],
      "metadata": {
        "id": "R_Eic51QPQ_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo RNN...\")\n",
        "modelo_rnn.fit(entradas_X_padded, saidas_y_one_hot, epochs=100, verbose=1)\n",
        "  # epochs: quandas vezes o modelo verá todo o conjunto de dados\n",
        "  # verbose: 1 para mostrar o progresso do treinamento\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkoH6i2pRUtH",
        "outputId": "e128a522-44df-4db5-8957-453206fc4d2e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo RNN...\n",
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0476 - loss: 2.9956\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.0476 - loss: 2.9877\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.0476 - loss: 2.9798\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: 2.9717\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0476 - loss: 2.9636\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1429 - loss: 2.9553\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1429 - loss: 2.9469\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1429 - loss: 2.9382\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1905 - loss: 2.9294\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1905 - loss: 2.9203\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: 2.9109\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2857 - loss: 2.9012\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2381 - loss: 2.8911\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2381 - loss: 2.8808\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2857 - loss: 2.8701\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2857 - loss: 2.8591\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2857 - loss: 2.8477\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2857 - loss: 2.8359\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2857 - loss: 2.8239\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2857 - loss: 2.8116\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2857 - loss: 2.7990\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.2857 - loss: 2.7862\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2857 - loss: 2.7732\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2857 - loss: 2.7600\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2857 - loss: 2.7467\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2857 - loss: 2.7334\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2857 - loss: 2.7200\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2857 - loss: 2.7066\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2857 - loss: 2.6931\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2857 - loss: 2.6796\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2857 - loss: 2.6659\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2857 - loss: 2.6521\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2857 - loss: 2.6381\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2857 - loss: 2.6238\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2857 - loss: 2.6091\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2857 - loss: 2.5941\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2857 - loss: 2.5786\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2857 - loss: 2.5626\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2857 - loss: 2.5461\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.2857 - loss: 2.5290\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2857 - loss: 2.5114\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2857 - loss: 2.4932\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3333 - loss: 2.4745\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3333 - loss: 2.4551\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3333 - loss: 2.4353\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3333 - loss: 2.4148\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3333 - loss: 2.3938\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3333 - loss: 2.3722\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3810 - loss: 2.3501\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4286 - loss: 2.3275\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4762 - loss: 2.3043\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4762 - loss: 2.2806\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4762 - loss: 2.2565\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4762 - loss: 2.2318\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5238 - loss: 2.2066\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5714 - loss: 2.1810\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5714 - loss: 2.1550\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6190 - loss: 2.1286\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6190 - loss: 2.1018\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6190 - loss: 2.0748\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6190 - loss: 2.0475\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6190 - loss: 2.0199\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6190 - loss: 1.9922\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6190 - loss: 1.9644\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6190 - loss: 1.9365\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6667 - loss: 1.9086\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6667 - loss: 1.8807\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6667 - loss: 1.8527\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7143 - loss: 1.8249\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7143 - loss: 1.7971\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7143 - loss: 1.7695\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7143 - loss: 1.7420\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7143 - loss: 1.7147\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7143 - loss: 1.6876\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7143 - loss: 1.6607\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7143 - loss: 1.6340\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7143 - loss: 1.6075\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7143 - loss: 1.5812\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7619 - loss: 1.5552\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7619 - loss: 1.5295\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7619 - loss: 1.5040\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7619 - loss: 1.4788\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7619 - loss: 1.4539\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7619 - loss: 1.4294\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7619 - loss: 1.4051\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7619 - loss: 1.3812\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8571 - loss: 1.3576\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8571 - loss: 1.3343\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8571 - loss: 1.3114\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9048 - loss: 1.2888\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9048 - loss: 1.2666\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9048 - loss: 1.2447\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9048 - loss: 1.2232\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9048 - loss: 1.2021\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9048 - loss: 1.1813\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9048 - loss: 1.1608\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9048 - loss: 1.1407\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9048 - loss: 1.1209\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9048 - loss: 1.1015\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9048 - loss: 1.0825\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resumo do que o código está executando:**\n",
        "\n",
        "---\n",
        "O código informa que vai começar a treinar um modelo chamado RNN, que vai aprender usando dados de entrada e saída várias vezes.\n",
        "\n",
        "* **epochs=100:** O modelo repete esse aprendizado 100 vezes\n",
        "\n",
        "* **verbose=1:** Mostra na tela como está indo o treinamento.\n",
        "\n",
        "Quando o aprendizado termina, aparece a mensagem \"Treinamento concluído!\"."
      ],
      "metadata": {
        "id": "xj8iuxxzP4wA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5° Passo: Usar o modelo para Previsão**"
      ],
      "metadata": {
        "id": "4uku3BNWPQ0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Função de Previsão:\n",
        "\n",
        "def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n",
        "\n",
        "    \"\"\"\n",
        "    Prevê a proxima palavra dado um texto base.\n",
        "    \"\"\"\n",
        "\n",
        "    # Converter o texto base para a sequência numérica\n",
        "    sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n",
        "\n",
        "    # Padronizar o comprimento da sequênca de entrada(precisa ter o mesmo formato que o treinamento)\n",
        "    # Atenção: max_seq_len deve ser o comprimento que as *entradas* foram pad_sequenciadas\n",
        "    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n",
        "\n",
        "    # Fazer a previsão\n",
        "    previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n",
        "\n",
        "    # Obter o índice da palavra com a maior probabilidade\n",
        "    indice_palavra_prevista = np.argmax(previsao_probabilidades)\n",
        "\n",
        "    # Converter o índice de volta para a palavra\n",
        "    for palavra, indice in tokenizer.word_index.items():\n",
        "      if indice == indice_palavra_prevista:\n",
        "        return palavra\n",
        "    return None # Caso a palavra não seja encontrada (improvável com o vocabulário ajustado)\n",
        "\n",
        "# Comprimento de entrada esperado pelo modelo\n",
        "# entradas_X_padded.shape[1] é o maxlen que usamos no pad_sequences para x\n",
        "comprimento_entrada_modelo = entradas_X_padded.shape[1]\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "print(\"\\n--- Testando com Modelo RNN ---\")\n",
        "\n",
        "texto_teste_1 = \"eu gosto de\"\n",
        "proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n",
        "print(f\"Texto: '{texto_teste_1}' -> Próxima palavra prevista: '{proxima_1}'\")\n",
        "\n",
        "texto_teste_2 = \"python é uma\"\n",
        "proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n",
        "print(f\"Texto: '{texto_teste_2}' -> Próxima palavra prevista: '{proxima_2}'\")\n",
        "\n",
        "texto_teste_3 = \"programar é divertido\"\n",
        "proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n",
        "print(f\"Texto: '{texto_teste_3}' -> Próxima palavra prevista: '{proxima_3}'\")\n",
        "\n",
        "texto_teste_4 = \"aprenda python e\"\n",
        "proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n",
        "print(f\"Texto: '{texto_teste_4}' -> Próxima palavra prevista: '{proxima_4}'\")\n",
        "\n",
        "# Exemplo com palavra fora do vocabulário ou sequecia que o modelo nunca viu antes\n",
        "texto_teste_5 = \"o sol brilha no\" # Palavras \"sol\" e \"brilha\" não estão no vocabulário\n",
        "proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n",
        "print(f\"Texto: '{texto_teste_5}' -> Próxima palavra prevista: '{proxima_5}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI0bwKXiSatX",
        "outputId": "f51da306-f588-4200-9380-000aa29c6085"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testando com Modelo RNN ---\n",
            "Texto: 'eu gosto de' -> Próxima palavra prevista: 'programar'\n",
            "Texto: 'python é uma' -> Próxima palavra prevista: 'linguagem'\n",
            "Texto: 'programar é divertido' -> Próxima palavra prevista: 'com'\n",
            "Texto: 'aprenda python e' -> Próxima palavra prevista: 'seja'\n",
            "Texto: 'o sol brilha no' -> Próxima palavra prevista: 'de'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação 2: Modelo de Rede Neural Rede Long Short-Term Memory**"
      ],
      "metadata": {
        "id": "DJxgaLGIUvsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1° Passo: Configuração de Ambiente no Google Colab**"
      ],
      "metadata": {
        "id": "3jtGgtMXVo-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhVlyphIWmX1",
        "outputId": "9ce43183-2872-4741-d846-b7311869dd49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resumo do que o código está executando:**\n",
        "\n",
        "---\n",
        "Importando a biblioteca"
      ],
      "metadata": {
        "id": "AnSChOB6auNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2° Passo: Preparação do Conjunto de Dados e Análise de sentimentos**"
      ],
      "metadata": {
        "id": "UWnRqWfHV-E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o conjunto de dados (Frases e Rótulos) para análise de sentimentos\n",
        "\n",
        "dados_sentimento = [\n",
        "    (\"este filme é ótimo e divertido\", \"positivo\"),\n",
        "    (\"eu adorei o livro, muito bom\", \"positivo\"),\n",
        "    (\"gostei muito da atuação dos atores\", \"positivo\"),\n",
        "    (\"o roteiro é fraco e chato\", \"negativo\"),\n",
        "    (\"não recomendo esse pessimo produto\", \"negativo\"),\n",
        "    (\"uma perda de tempo horrível\", \"negativo\"),\n",
        "    (\"ótimo trabalho, parabéns\", \"positivo\"),\n",
        "    (\"terrível experiência, nunca mais\", \"negativo\"),\n",
        "    (\"excelente serviço, muito eficiente\", \"positivo\"),\n",
        "    (\"que decepção, muito ruim\", \"negativo\"),\n",
        "    (\"aprendizagem de máquina é fascinante\", \"positivo\"),\n",
        "    (\"pln é um campo interessante\", \"positivo\"),\n",
        "    (\"este software travou varias vezes\", \"negativo\"),\n",
        "    (\"a interface é confusa e difícil\", \"negativo\"),\n",
        "    (\"o aplicativo é super útil e rápido\", \"positivo\"),\n",
        "]\n",
        "\n",
        "textos = [dado[0] for dado in dados_sentimento]\n",
        "sentimentos = [dado[1] for dado in dados_sentimento]\n",
        "\n",
        "print(f\"Total de frases: {len(textos)}\")\n",
        "print(f\"Exemplo de textos: {textos[:3]}\")\n",
        "print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hN0V6ilZQ2q",
        "outputId": "e3f67a01-29ef-494f-d37f-6bd50fa8316d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases: 15\n",
            "Exemplo de textos: ['este filme é ótimo e divertido', 'eu adorei o livro, muito bom', 'gostei muito da atuação dos atores']\n",
            "Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mapear sentimentos para números: converter \"positivo\" e \"negativo\" para 0 e 1\n",
        "mapeamento_sentimento = {'negativo': 0, 'positivo': 1}\n",
        "rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n",
        "\n",
        "print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB7-IomgZTpt",
        "outputId": "9adae1b7-e4ec-438d-9792-7888ff8568a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentimentos mapeados para números: [1 1 1 0 0 0 1 0 1 0 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização de Texto\n",
        "tokenizar = Tokenizer(num_words=None, oov_token=\"<unk>\")\n",
        "  # num_words=None para pegar todo o vocabulário\n",
        "  # oov_token para palavras desconhecidas\n",
        "tokenizer.fit_on_texts(textos)\n",
        "sequencias_numericas = tokenizer.texts_to_sequences(textos)\n",
        "\n",
        "total_palavras_vocab = len(tokenizer.word_index) + 1 # +1 para o 0 de padding/OOV\n",
        "\n",
        "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"\\nSequencias numéricas das frases: {sequencias_numericas}\")\n",
        "print(f\"\\nTamanho total do vocabulário: {total_palavras_vocab}\")\n",
        "\n",
        "# Padronizar o comprimento das sequências\n",
        "# Encontrar o comprimento da frase mais longa para padronizar\n",
        "max_len = max(len(s) for s in sequencias_numericas)\n",
        "print(f\"\\nComprimento máximo das sequências: {max_len}\")\n",
        "\n",
        "sequencias_padded = pad_sequences(sequencias_numericas, maxlen=max_len, padding='post')  # 'post' para adicionar zero no final\n",
        "print(f\"Sequencias após padding: \\n{sequencias_padded}\")\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    sequencias_padded, rotulos_numericos, test_size=0.2, random_state=42, stratify=rotulos_numericos\n",
        ")\n",
        "\n",
        "print(f\"\\nShape de X_treino: {X_treino.shape}\")\n",
        "print(f\"\\nShape de X_teste: {X_teste.shape}\")\n",
        "print(f\"\\nShape de y_treino: {y_treino.shape}\")\n",
        "print(f\"\\nShape de X_teste: {y_teste.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rWq0IlIZXt6",
        "outputId": "06503222-4866-4959-81d7-5177a00bc864"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra: índice): {'é': 1, 'e': 2, 'de': 3, 'python': 4, 'muito': 5, 'o': 6, 'eu': 7, 'gosto': 8, 'programar': 9, 'uma': 10, 'divertido': 11, 'este': 12, 'ótimo': 13, 'em': 14, 'linguagem': 15, 'poderosa': 16, 'com': 17, 'aprenda': 18, 'seja': 19, 'feliz': 20, 'aprender': 21, 'coisas': 22, 'novas': 23, 'filme': 24, 'adorei': 25, 'livro': 26, 'bom': 27, 'gostei': 28, 'da': 29, 'atuação': 30, 'dos': 31, 'atores': 32, 'roteiro': 33, 'fraco': 34, 'chato': 35, 'não': 36, 'recomendo': 37, 'esse': 38, 'pessimo': 39, 'produto': 40, 'perda': 41, 'tempo': 42, 'horrível': 43, 'trabalho': 44, 'parabéns': 45, 'terrível': 46, 'experiência': 47, 'nunca': 48, 'mais': 49, 'excelente': 50, 'serviço': 51, 'eficiente': 52, 'que': 53, 'decepção': 54, 'ruim': 55, 'aprendizagem': 56, 'máquina': 57, 'fascinante': 58, 'pln': 59, 'um': 60, 'campo': 61, 'interessante': 62, 'software': 63, 'travou': 64, 'varias': 65, 'vezes': 66, 'a': 67, 'interface': 68, 'confusa': 69, 'difícil': 70, 'aplicativo': 71, 'super': 72, 'útil': 73, 'rápido': 74}\n",
            "\n",
            "Sequencias numéricas das frases: [[12, 24, 1, 13, 2, 11], [7, 25, 6, 26, 5, 27], [28, 5, 29, 30, 31, 32], [6, 33, 1, 34, 2, 35], [36, 37, 38, 39, 40], [10, 41, 3, 42, 43], [13, 44, 45], [46, 47, 48, 49], [50, 51, 5, 52], [53, 54, 5, 55], [56, 3, 57, 1, 58], [59, 1, 60, 61, 62], [12, 63, 64, 65, 66], [67, 68, 1, 69, 2, 70], [6, 71, 1, 72, 73, 2, 74]]\n",
            "\n",
            "Tamanho total do vocabulário: 75\n",
            "\n",
            "Comprimento máximo das sequências: 7\n",
            "Sequencias após padding: \n",
            "[[12 24  1 13  2 11  0]\n",
            " [ 7 25  6 26  5 27  0]\n",
            " [28  5 29 30 31 32  0]\n",
            " [ 6 33  1 34  2 35  0]\n",
            " [36 37 38 39 40  0  0]\n",
            " [10 41  3 42 43  0  0]\n",
            " [13 44 45  0  0  0  0]\n",
            " [46 47 48 49  0  0  0]\n",
            " [50 51  5 52  0  0  0]\n",
            " [53 54  5 55  0  0  0]\n",
            " [56  3 57  1 58  0  0]\n",
            " [59  1 60 61 62  0  0]\n",
            " [12 63 64 65 66  0  0]\n",
            " [67 68  1 69  2 70  0]\n",
            " [ 6 71  1 72 73  2 74]]\n",
            "\n",
            "Shape de X_treino: (12, 7)\n",
            "\n",
            "Shape de X_teste: (3, 7)\n",
            "\n",
            "Shape de y_treino: (12,)\n",
            "\n",
            "Shape de X_teste: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3° Passo: Construção do Modelo LSTM**"
      ],
      "metadata": {
        "id": "HD6fH1SPV-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura do modelo LSTM\n",
        "\n",
        "modelo_lstm = Sequential()\n",
        "\n",
        "# Camada de Embedding: Converte os índices numéricos das palavras em vetores densos.\n",
        "# total_palavras_vocab: tamanho do vocabulário\n",
        "# 50: dimensão do vetor de embedding (pode ser ajustado)\n",
        "# input_length: comprimento padronizado das sequencias (max_len)\n",
        "modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n",
        "\n",
        "# Camada LSTM:\n",
        "# 64: número de unidades (neuronios) na camada LSTM. Define o tamanho do estado oculto e da célula de memória.\n",
        "# dropou: Um tipo de regularização para evitar overfitting (descarta aleatoriamente neuronios durante o treinamento)\n",
        "# recurrent_dropout: Dropout aplicado nas conexões recorrentes da LSTM.\n",
        "modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# 1: Um único neurônio de saída, pois é um problema de classificação binária (positivo/negativo).\n",
        "# activation='sigmoid': Função de ativação para classificação binária (produz um valor entre 0 e 1).\n",
        "\n",
        "modelo_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_lstm.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "bfJ1wnxrbUVd",
        "outputId": "5147a191-4071-4812-a16d-1b99bd273631"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4° Passo: Treinamento e Avaliação do Modelo**"
      ],
      "metadata": {
        "id": "VzqZPRUjWK0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo LSTM...\")\n",
        "\n",
        "historico = modelo_lstm.fit(\n",
        "    X_treino, y_treino,\n",
        "    epochs=50,\n",
        "    batch_size=2,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "  # epochs: número de vezes que o modelo verá todo o conjunto de dados de treinamento\n",
        "  # batch_size: número de amostras por atualização de gradiente.\n",
        "  # validation_split: % dos dados de treino usados para validação durante o treinamento( opcional, mas bom para monitorar o overfitting).\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0h_DIOZbgdw",
        "outputId": "53ce431a-7180-4129-f7e6-7bb3da3905f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - accuracy: 0.3306 - loss: 0.6969 - val_accuracy: 0.0000e+00 - val_loss: 0.6956\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8306 - loss: 0.6913 - val_accuracy: 0.5000 - val_loss: 0.6957\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7389 - loss: 0.6883 - val_accuracy: 0.0000e+00 - val_loss: 0.6973\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7931 - loss: 0.6841 - val_accuracy: 0.0000e+00 - val_loss: 0.6998\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.6816 - val_accuracy: 0.0000e+00 - val_loss: 0.7034\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.6607 - val_accuracy: 0.0000e+00 - val_loss: 0.7091\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.6462 - val_accuracy: 0.0000e+00 - val_loss: 0.7219\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.6019 - val_accuracy: 0.0000e+00 - val_loss: 0.7470\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.5421 - val_accuracy: 0.0000e+00 - val_loss: 0.8005\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.4357 - val_accuracy: 0.0000e+00 - val_loss: 0.9184\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.3031 - val_accuracy: 0.0000e+00 - val_loss: 1.1883\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1442 - val_accuracy: 0.0000e+00 - val_loss: 1.7154\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0317 - val_accuracy: 0.0000e+00 - val_loss: 2.4232\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.0000e+00 - val_loss: 3.1634\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.0000e+00 - val_loss: 3.7678\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.0000e+00 - val_loss: 4.1883\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.0000e+00 - val_loss: 4.4744\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0000e+00 - val_loss: 4.6745\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.0000e+00 - val_loss: 4.8159\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.0000e+00 - val_loss: 4.9189\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 4.9969\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.0000e+00 - val_loss: 5.0637\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.0000e+00 - val_loss: 5.1250\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 5.1786\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0000e+00 - val_loss: 5.2324\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0000e+00 - val_loss: 5.2837\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.3309\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0000e+00 - val_loss: 5.3760\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 5.4168\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.7276e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.4561\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0000e+00 - val_loss: 5.4972\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.5407\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.5269e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5854\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.3425e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6238\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.5076e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6608\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.4388e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6957\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.7180e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7310\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 5.7728\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.6137e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8109\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 7.9135e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8476\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.7030e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8808\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.1679e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9121\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.8029e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9435\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.2772e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9753\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.2221e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.0065\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.7517e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.0367\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.7456e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.0682\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.0052e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.0988\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.0804e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.1279\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.2118e-04 - val_accuracy: 0.0000e+00 - val_loss: 6.1575\n",
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia o modelo no conjunto de teste\n",
        "perda, acuracia = modelo_lstm.evaluate(X_teste, y_teste, verbose=0)\n",
        "print(f\"\\nAcurácia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n",
        "print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_prob = modelo_lstm.predict(X_teste)\n",
        "y_pred_classes = (y_pred_prob > 0.5).astype(int) # Converter probabilidades para 0 ou 1\n",
        "\n",
        "print(\"\\n --- Relatório de Classificação ---\")\n",
        "cm = confusion_matrix(y_teste, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negativo', 'positivo'], yticklabels=['negativo', 'positivo'])\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de confusão')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "8iIFfIk_bmgX",
        "outputId": "f2db63e5-c912-4795-c04e-cf31ed3c8bea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acurácia do modelo no conjunto de teste: 66.67%\n",
            "Perda do modelo no conjunto de teste: 1.4205\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933ms/step\n",
            "\n",
            " --- Relatório de Classificação ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5° Passo: Testando o modelo com novas frases**"
      ],
      "metadata": {
        "id": "TQIeDWEeVzU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando o modelo treinado\n",
        "\n",
        "def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n",
        "  \"\"\"\n",
        "  Prevê o sentimento de uma nova frase.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Converter a frase para sequencia numerica\n",
        "  sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n",
        "\n",
        "  # Se a frase tem palavras desconhecidas, o tokenizer pode retornar uma lista vazia ou valores 0\n",
        "  if not sequencia_numerica:\n",
        "    print(f\"Aviso: A frase '{frase_nova}' contém apenas palavras desconhecidas.\")\n",
        "    return \"Desconhecido\" # ou outra indicação\n",
        "\n",
        "  sequencia_numerica = sequencia_numerica[0] # Pega a primeira (e única) sequência\n",
        "\n",
        "  # Padronizar o comprimento da sequência de entrada\n",
        "  sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n",
        "\n",
        "  # Fazer a previsão (probabilidade)\n",
        "  probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n",
        "\n",
        "  # Inverter o mapeamento para obter o nome do sentimento\n",
        "  mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n",
        "\n",
        "  # Classificar com base no limiar de 0.5\n",
        "\n",
        "  if probabilidade_positiva >= 0.5:\n",
        "    return mapeamento_inverso[1] # 'positivo'\n",
        "  else:\n",
        "    return mapeamento_inverso[0] # 'negativo'\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "\n",
        "print(\"\\n --- Testando o Modelo LSTM com novas Frases ---\")\n",
        "\n",
        "frase_nova_1 = \"gostei muito do filme, excelente!\"\n",
        "sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: '{sentimento_1}'\")\n",
        "\n",
        "frase_nova_2 = \"odiei o livro, muito entediante\"\n",
        "sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: '{sentimento_1}'\")\n",
        "\n",
        "frase_nova_3 = \"a aula de pln é ótima!\"\n",
        "sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: '{sentimento_3}'\")\n",
        "\n",
        "frase_nova_4 = \"o atendimento foi péssimo\"\n",
        "sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: '{sentimento_4}'\")\n",
        "\n",
        "frase_nova_5 = \"esse produto não vale a pena, é caro\"\n",
        "sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: '{sentimento_5}'\")\n",
        "\n",
        "frase_nova_6 = \"o filme é legal\"\n",
        "sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: '{sentimento_6}'\")\n",
        "\n",
        "frase_nova_7 = \"isso é horrível, que tristeza\"\n",
        "sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: '{sentimento_7}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93TzhfIHbuRv",
        "outputId": "934348f4-2818-49bb-e477-d701c1e83cec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Testando o Modelo LSTM com novas Frases ---\n",
            "Frase: 'gostei muito do filme, excelente!' -> Sentimento previsto: 'positivo'\n",
            "Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: 'positivo'\n",
            "Frase: 'a aula de pln é ótima!' -> Sentimento previsto: 'positivo'\n",
            "Frase: 'o atendimento foi péssimo' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'o filme é legal' -> Sentimento previsto: 'negativo'\n",
            "Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: 'negativo'\n"
          ]
        }
      ]
    }
  ]
}